{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CodeClassificationDataset\n",
    "from pathlib import Path\n",
    "import sentencepiece as spm\n",
    "\n",
    "datadir = Path(\"/data/guesslang_data/Dataset/Data/train\")\n",
    "files = [x.suffix for x in datadir.glob(\"*.*\")]\n",
    "files = sorted(set(files))\n",
    "label_mapper = {k: i for i, k in enumerate(files)}\n",
    "label_mapper_i = {i: k for k, i in label_mapper.items()}\n",
    "\n",
    "tokenizer = spm.SentencePieceProcessor(model_file='../tokenizers/tok.model', num_threads=1)\n",
    "\n",
    "# dataset = CodeClassificationDataset(\n",
    "#     \"/data/guesslang_data/Dataset/Data\",\n",
    "#     \"train\",\n",
    "#     label_mapper,\n",
    "#     tokenizer, \n",
    "#     random_crop=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utf8_byte_tokenizer(text):\n",
    "    bytes_array = []\n",
    "    for char in text:\n",
    "        if 0 <= ord(char) <= 0x7F:\n",
    "            bytes_array.append(ord(char))\n",
    "        else:\n",
    "            continue\n",
    "    return bytes_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CodeClassificationDataset(\n",
    "    \"/data/guesslang_data/Dataset/Data\",\n",
    "    \"test\",\n",
    "    label_mapper,\n",
    "    tokenizer,\n",
    "    random_crop=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamodule import CodeClassificationDatamodule\n",
    "\n",
    "\n",
    "dm = CodeClassificationDatamodule(\n",
    "    \"/data/guesslang_data/Dataset/Data\",\n",
    "    label_mapper,\n",
    "    tokenizer,\n",
    "    random_crop=True,\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4541"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: nn.Module) -> str:\n",
    "    \"\"\"\n",
    "    Calculate the total number of parameters in a PyTorch model and format it in a human-readable way.\n",
    "\n",
    "    Parameters:\n",
    "    model (nn.Module): The PyTorch model.\n",
    "\n",
    "    Returns:\n",
    "    str: A formatted string showing the total number of parameters.\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    if total_params >= 1e6:\n",
    "        formatted_params = f\"{total_params / 1e6:.1f} M\"\n",
    "    elif total_params >= 1e3:\n",
    "        formatted_params = f\"{total_params / 1e3:.1f} K\"\n",
    "    else:\n",
    "        formatted_params = str(total_params)\n",
    "\n",
    "    return f\"{total_params:,} parameters -> {formatted_params}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_model import CodeClassificationModel\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Embedding(tokenizer.GetPieceSize(), 128),\n",
    "    # nn.Flatten(),\n",
    "    nn.Linear(128, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512*4096, 54),\n",
    ")\n",
    "\n",
    "batch = next(iter(dm.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"\"\"\n",
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Embedding(tokenizer.GetPieceSize(), 128),\n",
    "    # nn.Flatten(),\n",
    "    nn.Linear(128, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512*4096, 54),\n",
    ")\n",
    "\"\"\"\n",
    "encoded = tokenizer.encode(string)\n",
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'113,893,558 parameters -> 113.9 M'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 54])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Embedding(tokenizer.GetPieceSize(), 128),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128*4096, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 54),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.conv1 = nn.Conv1d(32, 128, (embed_dim)\n",
    "        self.pool = nn.MaxPool1d((2, 1))\n",
    "        self.fc1 = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # x = self.pool(x).squeeze(3)\n",
    "        # x = F.avg_pool2d(x, (x.size(2), 1)).squeeze(2)\n",
    "        # x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNNClassifier(4096, embed_dim=32, num_classes=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 32, 32], expected input[128, 4096, 32] to have 32 channels, but got 4096 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 14\u001b[0m, in \u001b[0;36mCNNClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 32, 32], expected input[128, 4096, 32] to have 32 channels, but got 4096 channels instead"
     ]
    }
   ],
   "source": [
    "cnn(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 54])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dm.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4096])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115238 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 9634/115238 [00:22<04:01, 437.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset))):\n\u001b[0;32m----> 5\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/ODS_NLP_Project/mlp/dataset.py:95\u001b[0m, in \u001b[0;36mCodeClassificationDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_data:\n\u001b[1;32m     94\u001b[0m     text, label \u001b[38;5;241m=\u001b[39m read_file((text, label))\n\u001b[0;32m---> 95\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_crop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(text), torch\u001b[38;5;241m.\u001b[39mtensor(label)\n",
      "File \u001b[0;32m~/ODS_NLP_Project/mlp/dataset.py:46\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[0;34m(string, tokenizer, mode, context_len, random_crop, pad_value)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m         string \u001b[38;5;241m=\u001b[39m string[:context_len]\n\u001b[0;32m---> 46\u001b[0m     bytes_list \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pad_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     48\u001b[0m     bytes_list \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(string)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentencepiece/__init__.py:549\u001b[0m, in \u001b[0;36mSentencePieceProcessor.Encode\u001b[0;34m(self, input, out_type, add_bos, add_eos, reverse, emit_unk_piece, enable_sampling, nbest_size, alpha, num_threads)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_EncodeAsImmutableProtoBatch(\u001b[38;5;28minput\u001b[39m, num_threads, enable_sampling, nbest_size,\n\u001b[1;32m    546\u001b[0m                                              alpha, add_bos, add_eos, reverse, emit_unk_piece)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 549\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_EncodeAsIds\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_sampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m                           \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_bos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_eos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memit_unk_piece\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    552\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_EncodeAsPieces(\u001b[38;5;28minput\u001b[39m, enable_sampling, nbest_size,\n\u001b[1;32m    553\u001b[0m                               alpha, add_bos, add_eos, reverse, emit_unk_piece)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentencepiece/__init__.py:319\u001b[0m, in \u001b[0;36mSentencePieceProcessor._EncodeAsIds\u001b[0;34m(self, text, enable_sampling, nbest_size, alpha, add_bos, add_eos, reverse, emit_unk_piece)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_EncodeAsIds\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, enable_sampling, nbest_size, alpha, add_bos, add_eos, reverse, emit_unk_piece):\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sentencepiece\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentencePieceProcessor__EncodeAsIds\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_sampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_bos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_eos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memit_unk_piece\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    x, y = dataset[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utf8_byte_tokenizer(text):\n",
    "    bytes_array = []\n",
    "    for char in text:\n",
    "        if 0 <= ord(char) <= 0x7F:\n",
    "            bytes_array.append(ord(char))\n",
    "        else:\n",
    "            continue\n",
    "    return bytes_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_code = \"\"\"\n",
    "#include <stdio.h>\n",
    "\n",
    "// akld\n",
    "\n",
    "int main() {\n",
    "    int a = 5, b = 10;\n",
    "    printf(\"Sum: %d\\\\n\", a + b);\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Example C++ code\n",
    "cpp_code = \"\"\"\n",
    "#include <iostream>\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "    int a = 5, b = 10;\n",
    "    cout << \"Sum: \" << (a + b) << endl;\n",
    "    return 0;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 35,\n",
       " 105,\n",
       " 110,\n",
       " 99,\n",
       " 108,\n",
       " 117,\n",
       " 100,\n",
       " 101,\n",
       " 32,\n",
       " 60,\n",
       " 105,\n",
       " 111,\n",
       " 115,\n",
       " 116,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 109,\n",
       " 62,\n",
       " 10,\n",
       " 117,\n",
       " 115,\n",
       " 105,\n",
       " 110,\n",
       " 103,\n",
       " 32,\n",
       " 110,\n",
       " 97,\n",
       " 109,\n",
       " 101,\n",
       " 115,\n",
       " 112,\n",
       " 97,\n",
       " 99,\n",
       " 101,\n",
       " 32,\n",
       " 115,\n",
       " 116,\n",
       " 100,\n",
       " 59,\n",
       " 10,\n",
       " 10,\n",
       " 105,\n",
       " 110,\n",
       " 116,\n",
       " 32,\n",
       " 109,\n",
       " 97,\n",
       " 105,\n",
       " 110,\n",
       " 40,\n",
       " 41,\n",
       " 32,\n",
       " 123,\n",
       " 10,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 116,\n",
       " 32,\n",
       " 97,\n",
       " 32,\n",
       " 61,\n",
       " 32,\n",
       " 53,\n",
       " 44,\n",
       " 32,\n",
       " 98,\n",
       " 32,\n",
       " 61,\n",
       " 32,\n",
       " 49,\n",
       " 48,\n",
       " 59,\n",
       " 10,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 99,\n",
       " 111,\n",
       " 117,\n",
       " 116,\n",
       " 32,\n",
       " 60,\n",
       " 60,\n",
       " 32,\n",
       " 34,\n",
       " 83,\n",
       " 117,\n",
       " 109,\n",
       " 58,\n",
       " 32,\n",
       " 34,\n",
       " 32,\n",
       " 60,\n",
       " 60,\n",
       " 32,\n",
       " 40,\n",
       " 97,\n",
       " 32,\n",
       " 43,\n",
       " 32,\n",
       " 98,\n",
       " 41,\n",
       " 32,\n",
       " 60,\n",
       " 60,\n",
       " 32,\n",
       " 101,\n",
       " 110,\n",
       " 100,\n",
       " 108,\n",
       " 59,\n",
       " 10,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 116,\n",
       " 117,\n",
       " 114,\n",
       " 110,\n",
       " 32,\n",
       " 48,\n",
       " 59,\n",
       " 10,\n",
       " 125,\n",
       " 10]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utf8_byte_tokenizer(cpp_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized bytes: [72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 33, 32, 32, 33, 32]\n"
     ]
    }
   ],
   "source": [
    "# Example string that includes ASCII and non-ASCII characters\n",
    "test_string = \"Hello, world! Привет мир! 大\"\n",
    "\n",
    "# Tokenize the string\n",
    "tokenized_bytes = utf8_byte_tokenizer(test_string)\n",
    "\n",
    "# Print the result\n",
    "print(\"Tokenized bytes:\", tokenized_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115238 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 7215/115238 [03:22<50:30, 35.65it/s]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset))):\n\u001b[0;32m----> 5\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/ODS_NLP_Project/mlp/dataset.py:88\u001b[0m, in \u001b[0;36mCodeClassificationDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_data:\n\u001b[1;32m     87\u001b[0m     text \u001b[38;5;241m=\u001b[39m read_file(text)\n\u001b[0;32m---> 88\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_crop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(text), torch\u001b[38;5;241m.\u001b[39mtensor(label)\n",
      "File \u001b[0;32m~/ODS_NLP_Project/mlp/dataset.py:33\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[0;34m(string, tokenizer, mode, context_len, random_crop, pad_value)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_text\u001b[39m(\n\u001b[1;32m     26\u001b[0m     string: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     27\u001b[0m     tokenizer: spm\u001b[38;5;241m.\u001b[39mSentencePieceProcessor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     pad_value: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m---> 33\u001b[0m     bytes_list \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(bytes_list)\n\u001b[1;32m     35\u001b[0m     pad_len \u001b[38;5;241m=\u001b[39m context_len \u001b[38;5;241m-\u001b[39m N\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentencepiece/__init__.py:549\u001b[0m, in \u001b[0;36mSentencePieceProcessor.Encode\u001b[0;34m(self, input, out_type, add_bos, add_eos, reverse, emit_unk_piece, enable_sampling, nbest_size, alpha, num_threads)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_EncodeAsImmutableProtoBatch(\u001b[38;5;28minput\u001b[39m, num_threads, enable_sampling, nbest_size,\n\u001b[1;32m    546\u001b[0m                                              alpha, add_bos, add_eos, reverse, emit_unk_piece)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 549\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_EncodeAsIds\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_sampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m                           \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_bos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_eos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memit_unk_piece\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    552\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_EncodeAsPieces(\u001b[38;5;28minput\u001b[39m, enable_sampling, nbest_size,\n\u001b[1;32m    553\u001b[0m                               alpha, add_bos, add_eos, reverse, emit_unk_piece)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentencepiece/__init__.py:319\u001b[0m, in \u001b[0;36mSentencePieceProcessor._EncodeAsIds\u001b[0;34m(self, text, enable_sampling, nbest_size, alpha, add_bos, add_eos, reverse, emit_unk_piece)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_EncodeAsIds\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, enable_sampling, nbest_size, alpha, add_bos, add_eos, reverse, emit_unk_piece):\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sentencepiece\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentencePieceProcessor__EncodeAsIds\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_sampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_bos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_eos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memit_unk_piece\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    x, y = dataset[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([258, 299, 305,  ...,   0,   0,   0]), tensor(13))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "datadir = Path(\"/data/guesslang_data/Dataset/Data/train\")\n",
    "files = [x.suffix for x in datadir.glob(\"*.*\")]\n",
    "files = sorted(set(files))\n",
    "label_mapper = {k: i for i, k in enumerate(files)}\n",
    "label_mapper_i = {i: k for k, i in label_mapper.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '.asm',\n",
       " 1: '.bat',\n",
       " 2: '.c',\n",
       " 3: '.cbl',\n",
       " 4: '.clj',\n",
       " 5: '.cmake',\n",
       " 6: '.coffee',\n",
       " 7: '.cpp',\n",
       " 8: '.cs',\n",
       " 9: '.css',\n",
       " 10: '.csv',\n",
       " 11: '.dart',\n",
       " 12: '.dm',\n",
       " 13: '.dockerfile',\n",
       " 14: '.erl',\n",
       " 15: '.ex',\n",
       " 16: '.f90',\n",
       " 17: '.go',\n",
       " 18: '.groovy',\n",
       " 19: '.hs',\n",
       " 20: '.html',\n",
       " 21: '.ini',\n",
       " 22: '.java',\n",
       " 23: '.jl',\n",
       " 24: '.js',\n",
       " 25: '.json',\n",
       " 26: '.kt',\n",
       " 27: '.lisp',\n",
       " 28: '.lua',\n",
       " 29: '.makefile',\n",
       " 30: '.matlab',\n",
       " 31: '.md',\n",
       " 32: '.ml',\n",
       " 33: '.mm',\n",
       " 34: '.pas',\n",
       " 35: '.php',\n",
       " 36: '.pm',\n",
       " 37: '.prolog',\n",
       " 38: '.ps1',\n",
       " 39: '.py',\n",
       " 40: '.r',\n",
       " 41: '.rb',\n",
       " 42: '.rs',\n",
       " 43: '.scala',\n",
       " 44: '.sh',\n",
       " 45: '.sql',\n",
       " 46: '.swift',\n",
       " 47: '.tex',\n",
       " 48: '.toml',\n",
       " 49: '.ts',\n",
       " 50: '.v',\n",
       " 51: '.vba',\n",
       " 52: '.xml',\n",
       " 53: '.yaml'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapper = {k: i for i, k in enumerate(files)}\n",
    "label_mapper_i = {i: k for k, i in label_mapper.items()}\n",
    "label_mapper_i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
